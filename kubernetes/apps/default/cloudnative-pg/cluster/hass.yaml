---
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: &currentCluster psql-v16-2
  namespace: default
spec:
  # using only 1 replica: very difficult to drain the node where postgres is running
  # using more than 1 replica: write amplification issues when leveraging replicated storage (e.g. ceph)
  instances: 2
  imageName: ghcr.io/cloudnative-pg/postgresql:16.0
  primaryUpdateStrategy: unsupervised
  storage:
    size: 15Gi
    storageClass: ceph-block
  enableSuperuserAccess: true
  superuserSecret:
    name: cloudnative-pg
  postgresql:
    parameters:
      max_connections: "300"
      shared_buffers: 512MB
  monitoring:
    enablePodMonitor: true
  resources:
    requests:
      memory: "512Mi"
    limits:
      memory: "1Gi"
  backup:
    retentionPolicy: 30d
    barmanObjectStore:
      wal:
        compression: bzip2
        maxParallel: 4
      destinationPath: s3://cloudnative-pg/
      endpointURL: &s3_url http://minio.default.svc.cluster.local:9000/
      serverName: *currentCluster
      s3Credentials:
        accessKeyId:
          name: cloudnative-pg
          key: S3_ACCESS_KEY
        secretAccessKey:
          name: cloudnative-pg
          key: S3_SECRET_KEY
  bootstrap:
    recovery:
      source: &previousCluster hass-psql-v16-1
  externalClusters:
    - name: *previousCluster
      barmanObjectStore:
        wal:
          compression: bzip2
          maxParallel: 4
        destinationPath: s3://cloudnative-pg/
        endpointURL: *s3_url
        serverName: *previousCluster
        s3Credentials:
          accessKeyId:
            name: cloudnative-pg
            key: S3_ACCESS_KEY
          secretAccessKey:
            name: cloudnative-pg
            key: S3_SECRET_KEY
